{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。\n",
    "\n",
    "课堂代码复现内容，查看名为Exersice-01.ipynb的文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 无人驾驶，文本翻译，语音识别，街景识别等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "        1、Github为管理多人开发项目提供了便利。通过在Github创建项目、将Github上的项目代码Pull到本地、将本地项目Push更新到Github，以方便多人合作完成项目代码。Github为开源网站，也方便大家分享交流项目代码。通过安装GIT工具以及Github Desktop工具，我们能够随时同步本地项目和Github的进度。\n",
    "        \n",
    "        2、Jupyter notebook 能够及时地返回编程结果，同时方便书写笔记，所以在分享、可视化编程过程方面比较有优势。Pycharm提供了更为专业、集中的开发环境。这两个工具结合，能方便我们面对不同的任务进行编程训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "概率模型是使用条件概率、贝叶斯概率公式等统计知识来计算某些随机变量之间的条件概率或者联合概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "在自然语言识别中，语音识别任务、文本翻译等都会使用到概率模型，去计算一句话出现的概率。\n",
    "在很多计算机视觉任务中，也会使用到概率模型。比如我们在使用GAN等模型去完成一些图像生成任务时，往往是使用的概率模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "1、在模式匹配之后，可能会产生多种匹配结果，我们可以使用概率去计算每种匹配结果的合理性，从而选出最佳匹配。\n",
    "\n",
    "2、但是基于模式匹配的算法，加入了更多的人工经验知识，需要预先定义完善的模式匹配规则，工程量巨大。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:语言模型就是基于一系列统计假设以及条件概率、贝叶斯公式来计算一句字符串的概率，使用概率来衡量语句的合理性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "  语音识别时，当将语音转化文字之后，可能有多个词序列，这是可以使用语言模型，来判断哪个词序列更为合理；\n",
    "  \n",
    "  机器翻译时，可以使用语言模型来判断转化过来的翻译文本，哪一句更为合理；\n",
    "  \n",
    "  在文本内容修复、文本预测的时候，由已知的文本内容，我们可以使用语言模型来预测缺失的文本为哪个词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "1-gram 语言模型在计算词序列的概率的时候，假设词与词之间是相互独立的。因此一个语句的出现概率可以写成：\n",
    "\n",
    "$P(w_1w_2w_3...w_n)=P(w_1)P(w_2)....P(w_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "优点：模型简单，计算一句话的概率比较简单，直接为每个词的概率的乘积\n",
    "\n",
    "缺点：模型假设苛刻，要求词与词之间相互独立，但是现实条件下，语句序列词与词之间是存在一定关系的，并非独立。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "1=2-gram 语言模型在计算词序列的概率的时候，假设词的出现与否只依赖于前一个词。因此一个语句的出现概率可以写成：\n",
    "\n",
    "$P(w_1w_2w_3...w_n)=P(w_1)P(w_2|w_1)P(w_3|w_1w_2)....P(w_n|w_1w_2...w_{n-1})~P(w_1)P(w_2|w_1)...P(w_n|w_{n-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动生成SQL语句，select语句\n",
    "SQL = \"\"\"\n",
    "SQL = SELECT  COLUMNS FROM TABLE WHERE CONDITIONS\n",
    "COLUMNS = * | COLS \n",
    "COLS = COL |COLS COL\n",
    "COL = Date, | Catograry, | Sales,\n",
    "TABLE = ORDRES_GZ | ORDERS_SH | ORDERS_BJ\n",
    "CONDITIONS = Date BETWEEN TO_DATE( start ,'YYYYMMDD') AND TO_DATE( end ,'YYYYMMDD')\n",
    "start = '20190101'| '20190201'| '20190301'\n",
    "end = '20190430' | '20190531' | '20190630'\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#点外卖的语法\n",
    "order = \"\"\"\n",
    "order = 打招呼 报明意图 报菜名 地址 ， 道谢 ！\n",
    "打招呼 = 你好, | 您好, | 打扰一下, \n",
    "报明意图 = 主语 行为\n",
    "主语 = 我要|我们要|我想|我需要|我可不可以\n",
    "行为 = 点单。|点菜。\n",
    "报菜名 = 我想要 菜名 。\n",
    "菜名 = 单个菜名 |单个菜名 、 菜名\n",
    "单个菜名 = 小龙虾| 红烧肉| 红烧排骨| 可乐鸡翅| 水煮鱼| 烤羊排 |水煮肉片| 口水鸡 | 酱板鸭 | 白灼虾 | 白切鸡\n",
    "地址 = 我家在 区名 小区名 楼号 房间号\n",
    "区名 = 天河区 | 白云区 | 海珠区 | 番禺区 | 越秀区 | 黄埔区\n",
    "小区名 = 保利云景 | 金燕花苑 | 白云家园 | 云山熹景\n",
    "楼号 = A栋 | B栋 |156栋 |257栋 |101栋\n",
    "房间号 = 502 | 201 | 101 | 804 | 603\n",
    "道谢 = 谢谢您 |谢谢 |多谢\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT * FROM ORDERS_BJ WHERE Date BETWEEN TO_DATE( '20190201' ,'YYYYMMDD') AND TO_DATE( '20190630' ,'YYYYMMDD')\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "def defined_grammar(gram_sent,split='='):\n",
    "    grammar_sentence = {}\n",
    "    for line in gram_sent.split('\\n'):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar_sentence[exp.strip()]=[s.split() for s in stmt.split('|')]\n",
    "    return grammar_sentence\n",
    "    \n",
    "\n",
    "def generate(gram,target):\n",
    "    if target not in gram: return target\n",
    "    expand = [generate(gram,t) for t in random.choice(gram[target])]#target可以扩展\n",
    "    return ' '.join([e if e!='/n' else '\\n'  for e in expand if e !='null'])\n",
    "\n",
    "grammar_sentence = defined_grammar(SQL,'=')\n",
    "generate(gram=grammar_sentence,target='SQL') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM ORDRES_GZ WHERE Date BETWEEN TO_DATE( '20190201' ,'YYYYMMDD') AND TO_DATE( '20190430' ,'YYYYMMDD')\n",
      "SELECT * FROM ORDERS_BJ WHERE Date BETWEEN TO_DATE( '20190101' ,'YYYYMMDD') AND TO_DATE( '20190430' ,'YYYYMMDD')\n",
      "SELECT * FROM ORDERS_BJ WHERE Date BETWEEN TO_DATE( '20190301' ,'YYYYMMDD') AND TO_DATE( '20190531' ,'YYYYMMDD')\n",
      "SELECT Date, Date, FROM ORDERS_SH WHERE Date BETWEEN TO_DATE( '20190101' ,'YYYYMMDD') AND TO_DATE( '20190630' ,'YYYYMMDD')\n",
      "SELECT Catograry, FROM ORDERS_BJ WHERE Date BETWEEN TO_DATE( '20190201' ,'YYYYMMDD') AND TO_DATE( '20190430' ,'YYYYMMDD')\n",
      "SELECT Date, FROM ORDERS_BJ WHERE Date BETWEEN TO_DATE( '20190201' ,'YYYYMMDD') AND TO_DATE( '20190531' ,'YYYYMMDD')\n",
      "SELECT * FROM ORDRES_GZ WHERE Date BETWEEN TO_DATE( '20190301' ,'YYYYMMDD') AND TO_DATE( '20190430' ,'YYYYMMDD')\n",
      "SELECT * FROM ORDERS_SH WHERE Date BETWEEN TO_DATE( '20190201' ,'YYYYMMDD') AND TO_DATE( '20190630' ,'YYYYMMDD')\n",
      "SELECT Catograry, Catograry, Date, FROM ORDRES_GZ WHERE Date BETWEEN TO_DATE( '20190201' ,'YYYYMMDD') AND TO_DATE( '20190531' ,'YYYYMMDD')\n",
      "SELECT Sales, FROM ORDRES_GZ WHERE Date BETWEEN TO_DATE( '20190101' ,'YYYYMMDD') AND TO_DATE( '20190430' ,'YYYYMMDD')\n"
     ]
    }
   ],
   "source": [
    "def generate_n(n,sentence,split,target):\n",
    "    for i in range(n):\n",
    "        grammar_sentence = defined_grammar(sentence,split)\n",
    "        print(generate(gram=grammar_sentence,target=target))\n",
    "    pass\n",
    "\n",
    "generate_n(10,SQL,'=','SQL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打扰一下,我需要点菜。我想要水煮肉片、水煮鱼。我家在越秀区金燕花苑257栋201，多谢！\n",
      "您好,我要点菜。我想要水煮鱼。我家在黄埔区保利云景156栋603，谢谢您！\n",
      "打扰一下,我想点菜。我想要红烧肉、水煮鱼、可乐鸡翅、红烧排骨、红烧肉。我家在天河区云山熹景156栋101，多谢！\n",
      "您好,我想点单。我想要可乐鸡翅。我家在越秀区白云家园101栋804，谢谢您！\n",
      "打扰一下,我想点菜。我想要小龙虾、小龙虾、红烧肉。我家在天河区保利云景101栋201，谢谢！\n",
      "您好,我需要点菜。我想要红烧排骨、水煮鱼。我家在黄埔区保利云景257栋804，谢谢！\n",
      "打扰一下,我要点单。我想要红烧肉、酱板鸭。我家在白云区金燕花苑101栋201，谢谢您！\n",
      "你好,我们要点单。我想要红烧肉。我家在黄埔区金燕花苑B栋502，谢谢您！\n",
      "打扰一下,我要点单。我想要小龙虾、可乐鸡翅。我家在海珠区金燕花苑A栋603，多谢！\n",
      "打扰一下,我可不可以点菜。我想要水煮鱼。我家在越秀区白云家园156栋804，谢谢您！\n"
     ]
    }
   ],
   "source": [
    "def generate(gram,target):\n",
    "    if target not in gram: return target\n",
    "    expand = [generate(gram,t) for t in random.choice(gram[target])]#target可以扩展\n",
    "    return ''.join([e if e!='/n' else '\\n'  for e in expand if e !='null'])\n",
    "\n",
    "generate_n(10,order,'=','order')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "sentences = []\n",
    "with open('../../Data/train.txt/train.txt','r',encoding='UTF-8') as f:\n",
    "    for line in f.readlines():\n",
    "        sentence =''.join(re.findall('[\\u4e00-\\u9fa5 0-9]+',line))#只提取汉字和数字\n",
    "        sentences.append(re.sub('^\\d+','',sentence).strip())#去掉每句话之前的数字编号，和首尾的空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['法律要求残疾保险吗',\n",
       " '债权人可以在死后人寿保险吗',\n",
       " '旅行者保险有租赁保险吗',\n",
       " '我可以开一辆没有保险的新车吗',\n",
       " '人寿保险的现金转出价值是否应纳税',\n",
       " '如何报告年金收入',\n",
       " '家庭保险涵盖什么',\n",
       " '什么是简单的退休计划',\n",
       " '社会保险残疾保险是什么',\n",
       " '汽车保险是否预付',\n",
       " '医疗保险部分盖什么',\n",
       " '退伍军人能否获得人寿保险',\n",
       " '我的房主保险是否包括失去的结婚戒指',\n",
       " '分配风险汽车保险如何工作',\n",
       " '我的男朋友可以加我的汽车保险吗',\n",
       " '我是否需要提交私人财产车祸索赔的警察报告',\n",
       " '全覆盖汽车保险盖修理',\n",
       " '人生在伊斯兰教中是否可以接受',\n",
       " '健康保险是否覆盖管道逆转',\n",
       " '如果您已经诊断为乳腺癌您可以获得多大的人寿保险']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80724\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "TOKEN = []\n",
    "for s in sentences:\n",
    "    TOKEN += jieba.cut(s)\n",
    "print(len(TOKEN))\n",
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['法律要求', '要求残疾', '残疾保险', '债权人可以', '可以在', '在死', '死后', '后人寿保险', '旅行者保险', '保险有']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.011604060677968e-12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################计算一个语句的概率\n",
    "def Prob_1(word):\n",
    "    return words_count[word]/len(TOKEN)\n",
    "\n",
    "TOKEN_2_gram = []\n",
    "for s in sentences:\n",
    "    token = list(jieba.cut(s))\n",
    "    TOKEN_2_gram += [''.join(token[i:i+2]) for i in range(len(token)-2)]\n",
    "\n",
    "####【课程代码是不是有问题 ，定义的Prob_2函数计算的是P(w1w2)的概率，而我们计算一句话的概率，需要的是P(w2|w1)的概率】\n",
    "words_count_2_gram = Counter(TOKEN_2_gram)\n",
    "def Prob_2(word1,word2):\n",
    "    if word1 + word2 in TOKEN_2_gram:\n",
    "        return words_count_2_gram[word1+word2]/len(TOKEN_2_gram)\n",
    "    else:\n",
    "        return 1/len(TOKEN_2_gram)\n",
    "print(TOKEN_2_gram[0:10])\n",
    "\n",
    "##计算一句话的概率\n",
    "def Sentence_Prob(sentence):\n",
    "    words = list(jieba.cut(sentence))\n",
    "    sent_prob = 1\n",
    "    for i,w in enumerate(words[:-1]):\n",
    "        sent_prob *= Prob_2(w,words[i+1])\n",
    "    return sent_prob\n",
    "Sentence_Prob('健康保险是不是包含')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好, 我需要 点菜。 我想要 白切鸡 、 水煮鱼 、 可乐鸡翅 、 水煮肉片 、 白切鸡 、 水煮肉片 、 水煮鱼 、 可乐鸡翅 。 我家在 海珠区 白云家园 A栋 101 ， 谢谢 ！\n"
     ]
    }
   ],
   "source": [
    "def generate_best(grammar,split,target,prob_model): # you code here\n",
    "    prob = [] #记录每个句子的概率\n",
    "    for i in range(100):\n",
    "        grammar_sentence = defined_grammar(grammar,split)\n",
    "        generate_sentence = generate(gram=grammar_sentence,target=target)\n",
    "        generate_sentence_clean = ''.join(re.findall('\\w+',generate_sentence))\n",
    "        prob.append((generate_sentence,Sentence_Prob(generate_sentence_clean)))\n",
    "    sentence_best = sorted(prob,key=lambda x:x[1])[0]\n",
    "    print(sentence_best[0])\n",
    "    \n",
    "    pass\n",
    "\n",
    "generate_best(grammar=order,split='=',target='order',prob_model=Sentence_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:我定义的语法是随机点外卖的语句，其中涉及到随机生成的地址，但是区+小区+门牌号的随机组合，在现实中可能并没有这样的地址。如果需要利用语言模型判断概率合理的话，应该使用更有针对性的数据据进行语言模型的训练，这就需要数据集中涉及到大量的地址库。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
